{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from cfg import get_config\n",
    "import PostProcessing\n",
    "from PostProcessing import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Code for obtain the predictions of the multi-step ahead prediction,  it parses de results of the simulations and saves the predictions in a file. '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Code for obtain the predictions of the multi-step ahead prediction,  it parses de results of the simulations and saves the predictions in a file. \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### FIlenames por Synthetic Traffic ######  \n",
    "\n",
    "\n",
    "emBB_filenames = []\n",
    "mMTC_filenames = []\n",
    "uRLLC_filenames = []\n",
    "for i in range(0, 7):\n",
    "    emBB_filenames.append('emBB_'+str(i))\n",
    "    mMTC_filenames.append('mMTC_'+str(i))\n",
    "    uRLLC_filenames.append('uRLLC_'+str(i))\n",
    "\n",
    "all_filenames = emBB_filenames + mMTC_filenames[:-1] + uRLLC_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Services for synthetic traffic ####\n",
    "services=all_filenames\n",
    "\n",
    "time_admission=[120]\n",
    "\n",
    "## Dataset Samples\n",
    "train_samples = 40320\n",
    "val_samples = 20160\n",
    "test_samples = 10080\n",
    "## input size\n",
    "input_size=480\n",
    "\n",
    "\n",
    "### Change the Alphas and time_decision_NP for the different experiments\n",
    "\n",
    "#FOR NP\n",
    "Alphas=['Alpha_0.75']\n",
    "time_decision_NP=[5,15,30,60,120]\n",
    "\n",
    "#FOR SP \n",
    "# Alphas=['Alpha_1.5']\n",
    "# time_decision_NP=[120]\n",
    "\n",
    "Simulations=[]\n",
    "for i in range(len(time_decision_NP)):\n",
    "    Simulations.append(f'T_dec_{time_decision_NP[i]}_Tadm_{time_admission[0]}/Simulation_1/')\n",
    "time_decision_SP=[120]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=get_config(services,Alphas,Simulations,time_admission,time_decision_NP,time_decision_SP,train_samples,val_samples,test_samples,input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loader=PostProcessing.Load_Data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Selection: Load_Type='AC_RA' == Admision control, Resource allocation. Load_Type='RRA' == ReResource allocation ####\n",
    "#### For the same predictions of MNO, Use AC_RA to obtain first predictions going to P1 and then RRA to obtain the second predictions going to P2 ####\n",
    "\n",
    "Load_Types=['AC_RA','RRA']\n",
    "\n",
    "Load_Type = Load_Types[1]\n",
    "tadm_folder=time_admission[0]\n",
    "\n",
    "Results_dir = f'./Capacity_Forecasting/Results/Synthetic_Results_noisy/{tadm_folder}/'\n",
    "Fpath_save_preds=f'./Results/Synthetic_Results_PREDS/{tadm_folder}/{Load_Type}/'\n",
    "\n",
    "Actuals=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:34<00:00,  1.73s/it]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.76it/s]\n",
      "100%|██████████| 20/20 [00:05<00:00,  3.50it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  6.86it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 13.68it/s]\n",
      "100%|██████████| 5/5 [00:56<00:00, 11.23s/it]\n"
     ]
    }
   ],
   "source": [
    "for alpha in Alphas:\n",
    "    for i in tqdm(range(len(Simulations))):\n",
    "        for service in tqdm(services):\n",
    "            Loader.save_preds(Results_dir,service,alpha,Simulations[i],time_admission[0],time_decision_NP[i],Fpath_save_preds,Load_type=Load_Type,Actuals=Actuals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RiverML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "09808f8dca6627cf736e90db716b681e01f819def718bfae8064c7785168ec8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
